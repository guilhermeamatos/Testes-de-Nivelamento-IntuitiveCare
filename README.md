# ğŸ§ªTestes de Nivelamento - IntuitiveCare

Este repositÃ³rio contÃ©m a soluÃ§Ã£o para os testes tÃ©cnicos propostos na etapa de nivelamento do processo seletivo da **IntuitiveCare**. O projeto foi desenvolvido com foco em clareza, organizaÃ§Ã£o, boas prÃ¡ticas de programaÃ§Ã£o e facilidade de avaliaÃ§Ã£o.

---

## ğŸ“ Estrutura do Projeto

Abaixo estÃ¡ a estrutura de diretorios e arquivos do repositÃ³rio, organizada por teste um diretorio para cada teste  
```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ api
â”‚Â Â  â”œâ”€â”€ backend
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ app.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ config.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ routes
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ search.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ utils
â”‚Â Â  â”‚Â Â      â””â”€â”€ csv_loader.py
â”‚Â Â  â””â”€â”€ frontend
â”‚Â Â      â”œâ”€â”€ README.md
â”‚Â Â      â”œâ”€â”€ babel.config.js
â”‚Â Â      â”œâ”€â”€ jsconfig.json
â”‚Â Â      â”œâ”€â”€ package-lock.json
â”‚Â Â      â”œâ”€â”€ package.json
â”‚Â Â      â”œâ”€â”€ public
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ favicon.ico
â”‚Â Â      â”‚Â Â  â””â”€â”€ index.html
â”‚Â Â      â”œâ”€â”€ src
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ App.vue
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ assets
â”‚Â Â      â”‚Â Â  â”‚Â Â  â””â”€â”€ logo.png
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ components
â”‚Â Â      â”‚Â Â  â”‚Â Â  â””â”€â”€ SearchOperadoras.vue
â”‚Â Â      â”‚Â Â  â””â”€â”€ main.js
â”‚Â Â      â””â”€â”€ vue.config.js
â”œâ”€â”€ data_transform
â”‚Â Â  â”œâ”€â”€ csv_transformer.py
â”‚Â Â  â”œâ”€â”€ main.py
â”‚Â Â  â”œâ”€â”€ pdf_extractor.py
â”‚Â Â  â””â”€â”€ tests
â”‚Â Â      â”œâ”€â”€ test_csv_transformer.py
â”‚Â Â      â””â”€â”€ test_pdf_extractor.py
â”œâ”€â”€ database
â”‚Â Â  â”œâ”€â”€ analytics
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ ano.sql
â”‚Â Â  â”‚Â Â  â””â”€â”€ trimestre.sql
â”‚Â Â  â”œâ”€â”€ ddl
â”‚Â Â  â”‚Â Â  â””â”€â”€ create_tables.sql
â”‚Â Â  â”œâ”€â”€ dml
â”‚Â Â  â”‚Â Â  â””â”€â”€ load_data.sql
â”‚Â Â  â”œâ”€â”€ etl
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ demonstracoes_data_cleaner.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ operadora_splitter.py
â”‚Â Â  â””â”€â”€ scraper
â”‚Â Â      â”œâ”€â”€ __init__.py
â”‚Â Â      â””â”€â”€ scraper_data.py
â”œâ”€â”€ encodin.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ web_scraping
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ config.py
    â”œâ”€â”€ main.py
    â”œâ”€â”€ scraper.py
    â”œâ”€â”€ tests
    â”‚Â Â  â”œâ”€â”€ test_scraper.py
    â”‚Â Â  â”œâ”€â”€ test_utils.py
    â”‚Â Â  â””â”€â”€ test_web_client.py
    â”œâ”€â”€ utils.py
    â””â”€â”€ web_client.py
```

__
## âš™ï¸ Requisitos

- Python 3.8+
- Node.js (para o frontend Vue)
- PostgreSQL (para testes de banco)
- Postman (para testes de API)

---

## ğŸ“¦ Como Executar

### 1. Clonar o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/intuitivecare-nivelamento.git
cd intuitivecare-nivelamento
```
### 2. Instalar as dependÃªncias

Crie e ative um ambiente virtual, depois instale as dependÃªncias:

```
python -m venv venv
# No Linux/Mac:
source venv/bin/activate
# No Windows:
venv\Scripts\activate
pip install -r requirements.txt
```
## ğŸš€ Executar os Scripts

Para rodar cada etapa do processo manualmente, siga as instruÃ§Ãµes abaixo a partir da raiz do projeto:

### 1. Web Scraping

Navegue atÃ© a raiz do projeto e execute:

```bash
 python .\web_scraping\main.py
 ```

### 2. TransformaÃ§Ã£o de dados 

Navegue atÃ© a raiz do projeto e execute:

```bash
 python .\data_transform\main.py
 ```

## 3. Banco de Dados

Para realizar essa etapa, primeiro Ã© preciso preparar os dados antes de cadastrÃ¡-los no PostgreSQL. Isso envolve executar o web scraping e a limpeza dos dados.

### 3.1. Preparar os Dados

#### 3.1.1 Executar o Web Scraping
Este script baixa os dados e extrai os arquivos CSV necessÃ¡rios:

```bash
python database/scraper/scraper_data.py
```
#### 3.1.2 Executar a Limpeza dos Dados
ApÃ³s o scraping, execute os scripts de limpeza para processar e formatar os dados:
```bash
python database/etl/demonstracoes_data_cleaner.py
python database/etl/operadora_splitter.py
```
#### 3.2. Cadastrar os Dados no PostgreSQL
Depois que os dados estiverem preparados, execute os scripts SQL para criar as tabelas e inserir os dados no banco de dados PostgreSQL.
```bash
psql -U seu_usuario -f .\database\ddl\create_tables.sql
psql -U seu_usuario -d db_guilherme -f .\database\dml\load_data.sql
```
### 3.3. Consultas e AnÃ¡lise dos Dados

ApÃ³s a inserÃ§Ã£o dos dados no PostgreSQL, Ã© hora de explorar as informaÃ§Ãµes. Para realizar as consultas:

3.3.1. **Abra seu SGBD preferido:**  
   Recomendamos o uso do pgAdmin para uma interface amigÃ¡vel.

3.3.2. **Conecte-se ao banco de dados:**  
   Utilize o banco de dados `db_guilherme`.

3.3.3. **Execute as consultas:**  
   No diretÃ³rio `database/analytics` vocÃª encontrarÃ¡ os scripts SQL com as consultas preparadas. Basta copiar e colar ou importar esses scripts no seu pgAdmin e executÃ¡-los para visualizar os resultados.

### 4. API

Para ver a API em plena execuÃ§Ã£o, siga os passos abaixo:

#### 4.1 Iniciar o Backend

No terminal, a partir da raiz do projeto, execute:

```bash
python api/backend/app.py
```
Isso iniciarÃ¡ o servidor backend.

#### 4.2 Iniciar o Frontend
Abra um novo terminal, navegue atÃ© o diretÃ³rio do frontend e execute:
```bash
npm install
npm run serve
```
Esses comandos instalarÃ£o as dependÃªncias do projeto Vue.js e iniciarÃ£o o servidor de desenvolvimento para o frontend.
ApÃ³s a execuÃ§Ã£o, acesse a URL exibida no terminal para visualizar a aplicaÃ§Ã£o em funcionamento.

### Testando a API com Postman

VocÃª pode testar nossa API utilizando a Postman Collection disponÃ­vel no link abaixo:

[API IntuitiveCare](https://yetrh3.postman.co/workspace/yetrh-Workspace~4b370f49-ad4c-49d8-9850-0ef50ca2a2c4/collection/23359082-bb27e278-df54-4aee-8805-bcf907d3af1e?action=share&creator=23359082
)

# Deploy na AWS

Foi realizado o deploy de uma aplicaÃ§Ã£o **Python** (back-end) e **Vue.js** (front-end) na AWS, disponibilizando a funcionalidade de **busca textual** pelas operadoras.

## EndereÃ§o de Acesso

- **IP PÃºblico**: [http://3.133.135.191/](http://3.133.135.191/)

A aplicaÃ§Ã£o estÃ¡ acessÃ­vel neste endereÃ§o, onde Ã© possÃ­vel realizar a busca e visualizar os resultados retornados pelo back-end.

---

### ObservaÃ§Ãµes Importantes

1. **Arquitetura**:
   - **Front-end (Vue.js)**: ResponsÃ¡vel pela interface da aplicaÃ§Ã£o.
   - **Back-end (Python)**: Gera os resultados da busca textual pelas operadoras.

2. **Nginx**: Configurado como servidor web e proxy reverso para encaminhar as requisiÃ§Ãµes ao back-end.

## Testes de Web Scraping e TransformaÃ§Ã£o de Dados

Foram implementados casos de teste para as etapas de **Web Scraping** e **TransformaÃ§Ã£o de Dados**. Para executar os testes, basta seguir as instruÃ§Ãµes abaixo:

### 1. Web Scraping

```bash
cd .\web_scraping\
python -m unittest discover
```
### 1. TransformaÃ§Ã£o de Dados
```bash
cd .\data_transform
python -m unittest discover
```
# Experimento de Performance

Foi realizado um experimento para testar a efetividade de uma soluÃ§Ã£o utilizando paralelismo para melhorar a performance de execuÃ§Ã£o do script `demonstracoes_data_cleaner.py`. Foi implementada uma versÃ£o com 4 threads disponÃ­veis no arquivo `demonstracoes_data_cleaner_multi_thread.py`.

**Resultados:**

- **MÃ©dia VersÃ£o Paralela:** 1:32 (92 segundos)
- **MÃ©dia VersÃ£o Sequencial:** 1:51 (111 segundos)
- **Melhoria de Performance:** Aproximadamente 17%





